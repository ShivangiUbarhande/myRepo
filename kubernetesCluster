Kubernetes cluster

 3 ways to create clusters:
1. Single Node cluster - MIniKube
2. Kubeadm -> for unmanaged clusters and on prem
3. Managed sevices - different service providers like aws, GCP, etc- costly


Namespace --> Deployment --> Replica Set --> POD --> Node
Pods are equivalent to containers
POds are scheduled on Node
2 types of Nodes - Master and Worker

Kubectl command works with master Node only.

Kubernetes Sevices- 3 types
Cluster IP  - communication in between components within a cluster(ingress/egress) traffic management
Node port  - make your component exposed to external world (dedicated range of ports)
API Gateway - To provide a domain for externally exposing (Acts as a load balancer)



kubectl get po -- show pods
kubectl get nodes
kubectl get no -- to get nodes
kubectl get no -o wide  --shows IP as well
kubectl run nginx-webapp --image nginx
kubectl get po
kubectl describe po nginx-webapp
kubectl get po -o wide  -- on which node my pod is launched(always gets launched on worker nodes only)
curl 192.34,78(IP address from abv command)----  -- will show nginx home page
kubectl get svc -- to see services -- by default we have ClusterIP service
kubectl expose pod nginx-webapp --type=NodePort --port=80
kubectl get svc
history
kubectl get ns -- shows namespaces
kubectl run redis-pod --image=redis
kubectl get po
kubectl describe po redis-pod 
kubectl run nginx-webapp --image=nginx --dry-run=client -o yaml  -- to get yaml of a pod

PODS creation:

Either via commandline or via yml
 Kubernetes is all about yml files


container creation via yaml:
      vi nginx-pod.yml
      apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx-container
    image: nginx
      kubectl create -f nginx-pod.yml
      kubectl get po
      kubectl get svc
      kubectl exec -it nginx-pod -- /bin/sh
      paste html file here
      kubectl expose pod nginx-pod --type=NodePort --port=80
      kubectl get svc
      history

-------------------------------------------------------------------------------
ReplicationController:

nginx-replicademo.yml
apiVersion: v1
kind: ReplicationController
metadata:
  name: nginx-rc
spec:
  replicas: 3
  template:
    metadata:
      name: nginx-pod
      labels:
        app: nginx-app
    spec:
      containers:
      - name: nginx-container
        image: nginx
        ports:
        - containerPort: 80
  selector:
    app: nginx-app

    3  vi nginx-replicademo.yml
    4  kubectl create -f nginx-replicademo.yml
    5  kubectl get po
    6  kubectl get rc
    7  history
    8  kubectl describe po nginx-rc-zdhvc
    9  kubectl get po
   10  kubectl delete po nginx-rc-bf9gb
   11  kubectl get po
   12  kubectl delete po --all
   13  kubectl get po
   kubectl scale rc nginx-rc --replicas=5   - to change replica

explanation:
yml
create
get rc
describe
 get po
delete 1 pod
get pod -- again 3 will 
----------------------------------------------------------------------------
Replica Set

nginx-replicasetdemo.yml-
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
spec:
  replicas: 3
  template:
    metadata:
      name: nginx-pod
      labels:
        app: nginx-app
        tier: frontend
    spec:
      containers:
      - name: nginx-container
        image: nginx
        ports:
        - containerPort: 80
  selector:
    matchLabels:
      app: nginx-app
    matchExpressions:
      - {key: tier, operator: In, values: [frontend]}

19  vi nginx-replicasetdemo.yml
   20  kubectl create -f nginx-replicasetdemo.yml
   21  kubectl get rs
   22  kubectl get po
   23  kubectl get po -o wide
   24  kubectl delete po nginx-rs-szz8v
   25  kubectl get po -o wide
   26  history

---------------------------------------------------------------------------------
Daemon-set
Launches 1 pod in 1 node or subset of nodes
Example to launch pod in each node

fluentd-daemonsetdemo.yml-
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-ds
spec:
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: gcr.io/google-containers/fluentd-elasticsearch:1.20
  selector:
    matchLabels:
      name: fluentd

vi fluentd-daemonsetdemo.yml
   28  kubectl create -f fluentd-daemonsetdemo.yml
   29  kubectl get ds
   30  kubectl get po
   31  kubectl get po -o wide
   32  kubectl delete po fluentd-ds-q9p54
   33  kubectl get po -o wide
   34  history

Example to launch pod in subsets of node
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ds
spec:
  template:
    metadata:
      labels:
        name: nginx
    spec:
      containers:
      - name: nginx-container
        image: nginx
      nodeSelector:
        disktype: ssd
  selector:
    matchLabels:
      name: nginx

3  kubectl get nodes
    4  kubectl get nodes --show-labels
    5  kubectl label nodes node01 disktype=ssd  -- adding label to a node to select only that node in daemonset.
    6  kubectl get nodes --show-labels
    7  ls
    8  vi fluentd-daemonsetdemo.yml
    9  kubectl create -f fluentd-daemonsetdemo.yml
   10  kubectl get ds
   11  kubectl get po
   12  kubectl get po -o wide
   13  kubectl delete po nginx-ds-ng85m
   14  kubectl get po -o wide
   15  history

will launch in only node01 bcause we have labeled it as disktype=ssd
labels can be any key and value

-------------------------------
init container

initcontainerdemo.yml -

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 5; done;']
  
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']



-----

myservicedemo.yml -

apiVersion: v1
kind: Service
metadata:
  name: myservice
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9376

kubectl get po
    4  vi initcontainerdemo.yml
    5  kubectl create -f initcontainerdemo.yml
    6  kubectl get po
    7  kubectl describe myapp-pod
    8  kubectl describe po myapp-pod
    9  kubectl get po
   10  kubectl describe po myapp-pod
   11  vi myservicedemo.yml
   12  kubectl create -f myservicedemo.yml
   13  kubectl get po
   14  kubectl describe po myapp-pod
   15  history
---------------------------------------------------
Deployment 

Deployment has replicaSet which has 10 containers of image redis , strategy used is recreate

deploymentDemo.yml-

multiple strategies:
Recreate, Rolling update,

1. Recreate

apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-deployment
  labels:
    app: redis

spec:
  replicas: 10
  selector:
    matchLabels:
      app: redis
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
        - name: redis-container
          image: redis:5.0

   16  vi deploymentDemo.yml
   17  kubectl create -f deploymentDemo.yml
   18  kubectl get deploy
   19  kubectl describe deploy redis-deployment
   20  kubectl get deploy
   21  kubectl get rs
   22  kubectl get po
   23  history

----------------------------
Edit existing deployment file to change image version and validate status through --show-labels and rollout command

kubectl get deploy
   35  kubectl rollout status deployment redis-deployment
   36  kubectl get po --show-labels
   37  kubectl edit deploy redis-deployment
   38  kubectl get po --show-labels
   39  kubectl rollout status deployment redis-deployment
   40  kubectl get po --show-labels
   41  kubectl get po 
   42  kubectl rollout status deployment redis-deployment
   43  history

--------------------------------------------
2. Rolling Update(default)

rollingupdateDemo.yml -

apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-deployment
  labels:
    app: redis

spec:
  replicas: 10
  selector:
    matchLabels:
      app: redis
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 2
  minReadySeconds: 10
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
        - name: redis-container
          image: redis:6.0

   12  vi rollingupdateDemo.yml
   13  kubectl create -f rollingupdateDemo.yml
   15  kubectl get deploy
   16  kubectl get rs
   17  kubectl get po
   18  kubectl rollout status deployment redis-deployment
   19  kubectl get po --show-labels
   20  kubectl edit deploy redis-deployment  -- it will directlt take inside yml , insert and change version of redis from 6.0 to 5.0
   21  kubectl get po --show-labels
   22  kubectl rollout status deployment redis-deployment  -- Will show how 1 by 1 rolling update is happening , pods are not terminated at once
   25  kubectl rollout status deployment redis-deployment
   30  kubectl set image deployment redis-deployment redis-container=redis:6.0.16 --record=true  --- Instead of making change in the yml we can change the version directly from command
   31  kubectl rollout status deployment redis-deployment
   32  kubectl rollout history deployment redis-deployment  -- shows how many updates have taken place on that deployment image
   33  kubectl get deploy redis-deployment -o wide
   34  kubectl rollout undo  deployment redis-deployment
   35  kubectl get deploy redis-deployment -o wide
   36  kubectl rollout history deployment redis-deployment
   37  history

--------------------------------------------------------------------------------
Blue and Green deployment
blue refers to older version containers and green to new version. At a time both will exists ANd once all traffic is moved to green blue will be deleted




-----------------------------------------------------------------------------
Canary deployment

deployment region wise . New version released to only 1 region and later on to other

------------------------------------------------------------------
Ansible, Helm chart for bundling K8s pakages, Docker Desktop with MIniKube extension





